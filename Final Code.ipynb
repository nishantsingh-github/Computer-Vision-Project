{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710b4104",
   "metadata": {},
   "source": [
    "Let’s import our required libraries first\n",
    "face_recognition is an ai model that scans and recognize human faces, cv2 is opencv-python package, csv will be used for manipulating data in csv file, os to handle files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b636b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a6aee5",
   "metadata": {},
   "source": [
    "Videocapture is a method of opencv that takes input (here source is 0 or default webcam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4930d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679514e",
   "metadata": {},
   "source": [
    "to train the modal with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anil_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Anil.jpeg\")\n",
    "Anil_encoding = face_recognition.face_encodings(Anil_image)[0]\n",
    "\n",
    "#Himanshu_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Himanshu.jpeg\")\n",
    "#Himanshu_encoding = face_recognition.face_encodings(Himanshu_image)[0]\n",
    "\n",
    "Nishant_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Nishant.jpeg\")\n",
    "Nishant_encoding = face_recognition.face_encodings(Nishant_image)[0]\n",
    "\n",
    "Pradumn_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Pradumn.jpeg\")\n",
    "Pradumn_encoding = face_recognition.face_encodings(Pradumn_image)[0]\n",
    "\n",
    "Sir_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Sir.jpeg\")\n",
    "Sir_encoding = face_recognition.face_encodings(Sir_image)[0]\n",
    "\n",
    "#Swati_image = face_recognition.load_image_file(\"C:/Users/RISHABH DIXIT/Desktop/Project/Photos/Swati.jpeg\")\n",
    "#Swati_encoding = face_recognition.face_encodings(Swati_image)[0]\n",
    "\n",
    "known_face_encoding = [\n",
    "Anil_encoding,\n",
    "#Himanshu_encoding,\n",
    "Nishant_encoding,\n",
    "Pradumn_encoding,\n",
    "Sir_encoding,\n",
    "# Swati_encoding \n",
    "]\n",
    "\n",
    "known_faces_names = [\n",
    "\"Anil Yadav\",\n",
    "#\"Himanshu Sharma\",\n",
    "\"Nishant Singh\",\n",
    "\"Pradumn Singh\",\n",
    "\"Puneet Sir\",\n",
    "#\"Swati\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d1611",
   "metadata": {},
   "source": [
    "students is a copy of know faces that we will use mark the attendance (basically we will remove names that are present), face_locations, face_encodings, face_names are empty lists for input image (we will compare with specific recognized face for recognition), current time is current time (as the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13dfbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = known_faces_names.copy()\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "s=True\n",
    "\n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "f = open(current_date+'.csv','w+',newline = '')\n",
    "lnwriter = csv.writer(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82d67b",
   "metadata": {},
   "source": [
    "we will create a infinite loop and store the incoming frame into frame variable , a new small frame variable is created to store resized image and the scale of decrement is 0.25% on both x and y rgb_small_variable will store the rgb equivalent of the small frame, we need this as face_recognition package used rgb format ,face_locations and face_encodings variables will store the face encoding and locations of incoming frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23536218",
   "metadata": {},
   "source": [
    "we will create a for loop to iterate on face_encoding values and inside for looop we will compare incoming encoding and locations with know ones and if its present we will recognise what is the name of that face (for more detailed explanation watch the video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c003e1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     _,frame \u001b[38;5;241m=\u001b[39m video_capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 3\u001b[0m     small_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     rgb_small_frame \u001b[38;5;241m=\u001b[39m small_frame[:,:,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,frame = video_capture.read()\n",
    "    small_frame = cv2.resize(frame,(0,0),fx=0.25,fy=0.25)\n",
    "    rgb_small_frame = small_frame[:,:,::-1]\n",
    "    if s:\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame,face_locations)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encoding,face_encoding)\n",
    "            name=\"Unknown\"\n",
    "            face_distance = face_recognition.face_distance(known_face_encoding,face_encoding)\n",
    "            best_match_index = np.argmin(face_distance)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_faces_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "            \n",
    "            if name in known_faces_names:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                bottomLeftCornerOfText = (10,100)\n",
    "                fontScale              = 1.5\n",
    "                fontColor              = (255,0,0)\n",
    "                thickness              = 3\n",
    "                lineType               = 2\n",
    " \n",
    "                cv2.putText(frame,name+' Present', \n",
    "                    bottomLeftCornerOfText, \n",
    "                    font, \n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    thickness,\n",
    "                    lineType)\n",
    "                \n",
    "        \n",
    "                if name in students:\n",
    "                    students.remove(name)\n",
    "                    print(students)\n",
    "                    current_time = now.strftime(\"%H-%M-%S\")\n",
    "                    lnwriter.writerow([name,current_time])\n",
    "    cv2.imshow(\"attendence system\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2437b72",
   "metadata": {},
   "source": [
    "if the name is present in students list remove it from there as the student is marked as present once , current time is updated in the csv using date time package , the final task is to display the user video stream and also a exit condition which in this case is press of button ‘q’, after this the only thing left is to release the video capture (close video input stream) destroy all opened windows and close the opened file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe19bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
